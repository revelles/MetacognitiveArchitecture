This section presents a more structured formalization of the
metacognitive architecture. The goal is not to fix a single canonical
formalism, but to show that L0--L3 can be modeled as operators over
instructions, states, and outputs, with clearly separated roles for
content and control.

\subsection*{Basic objects}

Let:
\begin{itemize}
    \item $\Sigma$ be the set of possible instructions (prompts,
    policies, context strings),
    \item $\mathcal{O}$ be the set of possible outputs, and
    \item $\mathcal{S}$ be the space of internal states of the system
    (including project history, active domains, and memory).
\end{itemize}

A bare language model can be idealized as a (possibly stochastic) map
\[
    f_{\text{LLM}} : \Sigma \times \mathcal{S}
      \to \mathcal{O} \times \mathcal{S}.
\]
We make no assumption here about how $f_{\text{LLM}}$ is implemented; it
could be any autoregressive or retrieval-augmented architecture.

\subsection*{Layer operators}

The metacognitive architecture introduces four classes of operators,
$L_0, L_1, L_2, L_3$, each acting on $(\sigma, s)$ or on candidate
outputs.

\begin{definition}[Global cognitive layer $L_0$]
The L0 layer is an operator
\[
    L_0 : \Sigma \times \mathcal{S} \to \Sigma \times \mathcal{S}
\]
that enforces global reasoning constraints. Typical effects include:
normalizing the instruction into an abstract $\rightarrow$ domain
$\rightarrow$ task structure, appending global anti-fabrication rules,
or imposing a fact / inference / unknown separation discipline.
\end{definition}

\begin{definition}[Domain reasoning layers $L_1^d$]
For each domain $d$ in some index set $\mathcal{D}$ (e.g., legal,
medical, AI-systems), there is a domain-specific layer
\[
    L_1^d : \Sigma \times \mathcal{S} \to \Sigma \times \mathcal{S}
\]
that specializes instructions to domain $d$, injecting ontologies,
local constraints, and validity conditions. A configuration may enable a
subset $\mathcal{D}_{\text{active}} \subseteq \mathcal{D}$.
\end{definition}

\begin{definition}[Project governance layer $L_2$]
The L2 layer manages project-level state. Given a project identifier
$p$ from some set of projects $\mathcal{P}$, we write
\[
    L_2^p : \Sigma \times \mathcal{S} \times \mathcal{D}_{\text{active}}
      \to \Sigma \times \mathcal{S}.
\]
Intuitively, $L_2^p$:
\begin{enumerate}[label=(\alph*)]
    \item selects which domain layers $L_1^d$ are active for project $p$,
    \item re-applies project constraints (e.g., prior commitments,
          safety requirements),
    \item maintains continuity by updating the project state component
          of $\mathcal{S}$.
\end{enumerate}
\end{definition}

\begin{definition}[Testing and enforcement layer $L_3$]
Given a candidate output $y \in \mathcal{O}$, an associated reasoning
trace $\tau$, and state $s \in \mathcal{S}$, the L3 layer produces an
enforcement decision
\[
    L_3 : \mathcal{O} \times \mathcal{T} \times \mathcal{S}
      \to \{ \text{accept}, \text{revise}, \text{reject} \}
\]
for some space of traces $\mathcal{T}$. In the case $\text{revise}$,
$L_3$ may also emit a refined instruction $\sigma_{\text{rev}}$ to be
fed back into the pipeline.
\end{definition}

\subsection*{Execution pipeline}

A single reasoning episode under project $p \in \mathcal{P}$ proceeds as
follows. Given an initial instruction $\sigma_0 \in \Sigma$ and state
$s_0 \in \mathcal{S}$:

\begin{enumerate}[label=(\roman*)]
    \item \textbf{Global normalization (L0).}
    \[
        (\sigma_1, s_1) = L_0(\sigma_0, s_0).
    \]

    \item \textbf{Domain specialization (L1).}
    Let $\mathcal{D}_{\text{active}}$ be the set of domain layers
    chosen for project $p$. We apply them in some admissible order
    (e.g., a fixed total order or a partial order resolved by $L_2$):
    \[
        (\sigma_2, s_2)
           = \Big( \prod_{d \in \mathcal{D}_{\text{active}}} L_1^d \Big)
             (\sigma_1, s_1).
    \]

    \item \textbf{Project governance (L2).}
    \[
        (\sigma_3, s_3)
           = L_2^p(\sigma_2, s_2, \mathcal{D}_{\text{active}}).
    \]

    \item \textbf{Base model call.}
    \[
        (y, s_4) = f_{\text{LLM}}(\sigma_3, s_3).
    \]
    During this step, a reasoning trace $\tau$ is also accumulated
    (e.g., chain-of-thought, tool calls, or intermediate states).

    \item \textbf{Testing and enforcement (L3).}
    L3 evaluates $(y, \tau, s_4)$:
    \[
        d = L_3(y, \tau, s_4).
    \]
    If $d = \text{accept}$, the system releases $y$. If $d =
    \text{reject}$, the output is withheld. If $d = \text{revise}$,
    the system obtains a revised instruction $\sigma_{\text{rev}}$ and
    may re-enter the pipeline at step (i) or (ii).
\end{enumerate}

We call this composition the \emph{governed reasoning pipeline} for
project $p$.

\subsection*{Separation of content and control}

The architecture prescribes a structural separation:

\begin{itemize}
    \item Content-producing components are $f_{\text{LLM}}$ together
    with the instruction transformations in L0 and L1.
    \item Control-governing components are $L_2$ and $L_3$, which
    decide which domains are active, how project state evolves, and
    whether candidate outputs are acceptable.
\end{itemize}

This separation can be made precise by viewing $L_2$ and $L_3$ as
operating on a \emph{meta-level} configuration that is not writable by
$L_1^d$ or $f_{\text{LLM}}$ directly. One can then reason about
invariants such as:

\begin{itemize}
    \item domain isolation (no project may activate conflicting domain
          rules simultaneously);
    \item anti-fabrication discipline (L3 rejects outputs that violate
          L0's fact / inference / unknown separation);
    \item continuity (L2 re-applies project constraints across
          episodes).
\end{itemize}

These invariants are enforced by construction at the level of the
pipeline, rather than as ad-hoc prompt instructions. A more detailed
formal treatment could use transition systems or modal logics to reason
about reachable states and safety properties, but the operator view
above is sufficient to capture the intended governance semantics.
